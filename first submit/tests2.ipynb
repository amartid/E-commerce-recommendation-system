{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 14.613240003585815\n",
      "Time elapsed: 83.48160600662231\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from pathlib import Path # working with paths\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import bisect\n",
    "from itertools import product\n",
    "import shutil\n",
    "import concurrent.futures\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "# https://www.kaggle.com/code/columbia2131/otto-read-a-chunk-of-jsonl-to-manageable-df/\n",
    "\n",
    "# Setting data paths with pathlib\n",
    "data_path = Path('/home/mai22042/otto/data')\n",
    "train_path = data_path/'train.jsonl'\n",
    "test_path = data_path/'test.jsonl'\n",
    "sample_sub_path = Path('sample_submission.csv')\n",
    "\n",
    "from enum import Enum\n",
    "class RName(Enum):\n",
    "    CLICK = 'clicks'\n",
    "    CART = 'carts'\n",
    "    ORDER = 'orders'\n",
    "\n",
    "    def __str__(self):\n",
    "        return '%s' % self.name\n",
    "    def __repr__(self):\n",
    "        return '%s' % self.name\n",
    "        \n",
    "# Set aliases\n",
    "CLICK=RName.CLICK\n",
    "CART=RName.CART\n",
    "ORDER=RName.ORDER\n",
    "\n",
    "# create a dict with key [aid,type], val (session)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "class DT3:\n",
    "    def init_helper(self, chunk):\n",
    "        for session, events in zip(chunk['session'].tolist(), chunk['events'].tolist()):\n",
    "            for event in events:\n",
    "                key = event[\"aid\"], RName(event['type'])\n",
    "                if key not in self.products.keys():\n",
    "                    self.products[key] = set()\n",
    "                self.products[key].add(session)\n",
    "\n",
    "    def __init__(self, chunks, i=None, j=None, sampling=False):\n",
    "        self.products = {}\n",
    "        samples = []\n",
    "        if sampling:\n",
    "            samples = random.sample(range(34),1)\n",
    "            samples.sort()\n",
    "            print(samples)\n",
    "        for e, chunk in enumerate(chunks):\n",
    "            if (i==None and j==None) or (i<=e and j>e):\n",
    "                if sampling:\n",
    "                    if e in samples:\n",
    "                        print(\"test chunk number\",e)\n",
    "                        self.init_helper(chunk)\n",
    "                else:\n",
    "                    print(\"test chunk number\",e)\n",
    "                    self.init_helper(chunk)\n",
    "\n",
    "class DT2:\n",
    "    def init_helper(self, chunk):\n",
    "        for session, events in zip(chunk['session'].tolist(), chunk['events'].tolist()):\n",
    "            for event in events:\n",
    "                aid = event[\"aid\"]\n",
    "                key = session, RName(event['type'])\n",
    "                if key not in self.sessions.keys():\n",
    "                    self.sessions[key] = set()\n",
    "                self.sessions[key].add(aid)\n",
    "\n",
    "    def __init__(self, chunks, i=None, j=None, sampling=False):\n",
    "        self.sessions = {}\n",
    "        samples = []\n",
    "        if sampling:\n",
    "            samples = random.sample(range(34),1)\n",
    "            samples.sort()\n",
    "            print(samples)\n",
    "        for e, chunk in enumerate(chunks):\n",
    "            if (i==None and j==None) or (i<=e and j>e):\n",
    "                if sampling:\n",
    "                    if e in samples:\n",
    "                        print(\"test chunk number\",e)\n",
    "                        self.init_helper(chunk)\n",
    "                else:\n",
    "                    print(\"test chunk number\",e)\n",
    "                    self.init_helper(chunk)\n",
    "\n",
    "# Loading .jsonl file and creating DT object\n",
    "#start =time.time()\n",
    "#test_chunks  = pd.read_json(data_path / 'test.jsonl', lines=True, chunksize=400000)\n",
    "#test = DT3(test_chunks)\n",
    "#print (\"Time elapsed:\", time.time() - start)\n",
    "#del test_chunks # Delete chunks\n",
    "\n",
    "#                   CREATING TRAIN DT3\n",
    "\n",
    "# Loading .jsonl file and creating DT object\n",
    "# start =time.time()\n",
    "# train_chunks = pd.read_json(data_path / 'train.jsonl', lines=True, chunksize=400000)\n",
    "# train = DT3(train_chunks)\n",
    "# print (\"Time elapsed:\", time.time() - start)\n",
    "# del train_chunks # Delete chunks\n",
    "\n",
    "#                   SAVING TRAIN DT3\n",
    "\n",
    "# Saving object on pickle file\n",
    "\n",
    "# start =time.time()\n",
    "# with open('train_full_dt3.dat', 'wb') as f:\n",
    "#     pickle.dump(train, f)\n",
    "# print (\"Time elapsed:\", time.time() - start)\n",
    "\n",
    "\n",
    "\n",
    "#                   LOAD TRAIN DT3 FROM PICKLE FILE\n",
    "\n",
    "# Loading object from pickle file\n",
    "\n",
    "start =time.time()\n",
    "train = pickle.load(open(\"train_full_dt3.dat\", \"rb\"))\n",
    "print (\"Time elapsed:\", time.time() - start)\n",
    "\n",
    "# Loading .jsonl file and creating DT object\n",
    "# start =time.time()\n",
    "# train_chunks = pd.read_json(data_path / 'train.jsonl', lines=True, chunksize=400000)\n",
    "# traindt2 = DT2(train_chunks)\n",
    "# print (\"Time elapsed:\", time.time() - start)\n",
    "# del train_chunks # Delete chunks\n",
    "#                   SAVING TRAIN DT3\n",
    "\n",
    "# Saving object on pickle file\n",
    "\n",
    "# start =time.time()\n",
    "# with open('train_full_dt2.dat', 'wb') as f:\n",
    "#     pickle.dump(traindt2, f)\n",
    "# print (\"Time elapsed:\", time.time() - start)\n",
    "\n",
    "#                   LOAD TRAIN DT2 FROM PICKLE FILE\n",
    "\n",
    "# Loading object from pickle file\n",
    "\n",
    "start =time.time()\n",
    "traindt2 = pickle.load(open(\"train_full_dt2.dat\", \"rb\"))\n",
    "print (\"Time elapsed:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[108125, 1460571, 29735, 184976, 95488, 1502122, 1733943, 959208, 322370, 231487, 756588, 832192, 554660, 801774, 1083665, 166037, 1603001, 673407, 1586171, 1196256, 620545, 332654, 819288, 199409, 1236775, 986164, 1645990, 102345, 794192, 1022566]\n",
      "dict_items([(108125, -1), (1460571, -2), (29735, -3), (184976, -4), (95488, -5), (1502122, -6), (1733943, -7), (959208, -8), (322370, -9), (231487, -10), (756588, -11), (832192, -12), (554660, -13), (801774, -14), (1083665, -15), (166037, -16), (1603001, -17), (673407, -18), (1586171, -19), (1196256, -20), (620545, -21), (332654, -22), (819288, -23), (199409, -24), (1236775, -25), (986164, -26), (1645990, -27), (102345, -28), (794192, -29), (1022566, -30)])\n"
     ]
    }
   ],
   "source": [
    "class Sugest:\n",
    "    def __init__(self, list_of_sets):\n",
    "        self.product_count = {}\n",
    "        self.add_more(list_of_sets)\n",
    "\n",
    "    def add_more(self,list_of_sets):\n",
    "        for i in list_of_sets:\n",
    "            if i!=None:\n",
    "                for p in i:\n",
    "                    self._add(p)\n",
    "\n",
    "    def reset_to_top(self):\n",
    "        self.product_count=self.backup.copy()\n",
    "\n",
    "    def _add(self, product):\n",
    "        if product in self.product_count.keys():\n",
    "            if self.product_count[product]<0:\n",
    "                self.product_count[product]=1\n",
    "            else:\n",
    "                self.product_count[product]+=1\n",
    "        else:\n",
    "            self.product_count[product]=1\n",
    "\n",
    "    def top(self):\n",
    "        sorted_items = self.result(30)\n",
    "        tmp_dict={}\n",
    "        for e,i in enumerate(sorted_items):\n",
    "            tmp_dict[i]=int(-1-e)\n",
    "        self.product_count=tmp_dict\n",
    "        self.backup=tmp_dict.copy() #copy\n",
    "        \n",
    "\n",
    "    def result(self, number=20):\n",
    "        return  [\n",
    "            key for (key, value) in sorted(\n",
    "                self.product_count.items(), key=lambda x: x[1],reverse=True\n",
    "                )\n",
    "            ][:number]\n",
    "\n",
    "# get top products of train\n",
    "train_click_sets=[traindt2.sessions.get(tid) for tid in traindt2.sessions.keys() if tid[1]==CLICK]\n",
    "top_click=Sugest(train_click_sets)\n",
    "print(top_click.result(30))\n",
    "train_cart_sets=[traindt2.sessions.get(tid) for tid in traindt2.sessions.keys() if tid[1]==CART]\n",
    "top_cart=Sugest(train_cart_sets)\n",
    "train_order_sets=[traindt2.sessions.get(tid) for tid in traindt2.sessions.keys() if tid[1]==ORDER]\n",
    "top_order=Sugest(train_order_sets)\n",
    "\n",
    "top_click.top()\n",
    "top_cart.top()\n",
    "top_order.top()\n",
    "print(top_click.product_count.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(108125, -1), (1460571, -2), (29735, -3), (184976, -4), (95488, -5), (1502122, -6), (1733943, -7), (959208, -8), (322370, -9), (231487, -10), (756588, -11), (832192, -12), (554660, -13), (801774, -14), (1083665, -15), (166037, -16), (1603001, -17), (673407, -18), (1586171, -19), (1196256, -20), (620545, -21), (332654, -22), (819288, -23), (199409, -24), (1236775, -25), (986164, -26), (1645990, -27), (102345, -28), (794192, -29), (1022566, -30)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(top_click.product_count.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "test_chunks  = pd.read_json(data_path / 'test.jsonl', lines=True, chunksize=400000)\n",
    "\n",
    "\n",
    "def r_type(set_a, set_b):\n",
    "    if set_a==None or set_b==None:\n",
    "        return 0\n",
    "    if set_a == 0 or set_b == 0 :\n",
    "        return 0\n",
    "    intersection_len = len(set_a&set_b)\n",
    "    union_len = len(set_a|set_b)\n",
    "    if intersection_len == 0 or union_len == 0 :\n",
    "        return 0\n",
    "    else:\n",
    "        return intersection_len / union_len\n",
    "\n",
    "headerList = ['session_type','labels']\n",
    "with open(\"test_output_full\"+\".csv\", 'w') as file:\n",
    "    dw = csv.DictWriter(file, delimiter=',', fieldnames=headerList)\n",
    "    dw.writeheader()\n",
    "\n",
    "for chunk in test_chunks:\n",
    "    for session, events in tqdm(zip(chunk['session'].tolist(), chunk['events'].tolist())):\n",
    "        train_session_set=set()\n",
    "        test_product_click=set()\n",
    "        test_product_cart=set()\n",
    "        test_product_order=set()\n",
    "        for event in events:\n",
    "            event_type = RName(event['type'])\n",
    "            aid = event[\"aid\"]\n",
    "            if event_type==CART:\n",
    "                test_product_cart.add(aid)\n",
    "            elif event_type==ORDER:\n",
    "                test_product_order.add(aid)\n",
    "            else:\n",
    "                test_product_click.add(aid)\n",
    "            \n",
    "            key_train = aid,event_type\n",
    "            key_test = session,event_type\n",
    "            if key_train in train.products.keys():\n",
    "                train_session_set|=train.products[key_train]\n",
    "                \n",
    "        with open(\"test_output_full\"+\".csv\", 'a+') as f:\n",
    "            rscores=[]\n",
    "            for session_train in train_session_set:\n",
    "                r_click=r_type(test_product_click,traindt2.sessions.get((session_train,CLICK)))\n",
    "                r_cart=r_type(test_product_cart,traindt2.sessions.get((session_train,CART)))\n",
    "                r_order=r_type(test_product_order,traindt2.sessions.get((session_train,ORDER)))\n",
    "                r_score=r_click*0.1+r_cart*0.3+r_order*0.6\n",
    "                rscores.append((session_train, r_click,r_cart,r_order,r_score))\n",
    "                if len(rscores)>10000:\n",
    "                    rscores=sorted(rscores, key= lambda x:x[4], reverse=True)[:20]\n",
    "            if len(rscores)>20:\n",
    "                rscores=sorted(rscores, key= lambda x:x[4], reverse=True)[:20]\n",
    "            # #calculate products for each test session after having 20 best train sesisisisis\n",
    "            train_top_session_id=[rscores[0] for rscores in rscores]\n",
    "            train_rscore_products_click=[traindt2.sessions.get((tid,CART)) for tid in train_top_session_id]#list of sets\n",
    "            train_rscore_products_cart=[traindt2.sessions.get((tid,CLICK)) for tid in train_top_session_id]#list of sets\n",
    "            train_rscore_products_order=[traindt2.sessions.get((tid,ORDER)) for tid in train_top_session_id]#list of sets\n",
    "            \n",
    "            top_click.add_more(train_rscore_products_click)\n",
    "            top_cart.add_more(train_rscore_products_cart)\n",
    "            top_order.add_more(train_rscore_products_order)\n",
    "            \n",
    "            sugest_click=top_click.result()\n",
    "            sugest_cart=top_cart.result()\n",
    "            sugest_order=top_order.result()\n",
    "            \n",
    "            top_click.reset_to_top()\n",
    "            top_cart.reset_to_top()\n",
    "            top_order.reset_to_top()\n",
    "\n",
    "            f.write(str(session)+\"_\"+CLICK.value+\",\"+\" \".join(map(str,sugest_click))+\"\\n\")\n",
    "            f.write(str(session)+\"_\"+CART.value+\",\"+\" \".join(map(str,sugest_cart))+\"\\n\")\n",
    "            f.write(str(session)+\"_\"+ORDER.value+\",\"+\" \".join(map(str,sugest_order))+\"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[582150, 1095682, 108125, 1460571, 29735, 184976, 95488, 1502122, 1733943, 959208, 322370, 231487, 756588, 832192, 554660, 801774, 1083665, 166037, 1603001, 673407]\n",
      "[582150, 1095682, 108125, 1460571, 29735, 184976, 95488, 1502122, 1733943, 959208, 322370, 231487, 756588, 832192, 554660, 801774, 1083665, 166037]\n"
     ]
    }
   ],
   "source": [
    "print(sugest_click)\n",
    "print(sugest_click[:20-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing stuff from dt objects\n",
    "for i in range(5):\n",
    "    print('Session i:',traindt.products[i][0])\n",
    "    print('Contains this list:')\n",
    "    list=traindt.products[i]\n",
    "    for j, item in enumerate(list):\n",
    "        if j == 0:\n",
    "            print('Session i:',item)\n",
    "        elif j == 1:\n",
    "            print('Clicks:',item)\n",
    "        elif j == 2:\n",
    "            print('Carts:',item)\n",
    "        else:\n",
    "            print('Orders:',item)\n",
    "            \n",
    "for i in range(5):\n",
    "    print('or like this:')\n",
    "    print(traindt.products[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59625, CLICK)\n"
     ]
    }
   ],
   "source": [
    "print(list(test.products.keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test sessions:  1671803\n",
      "train sessions:  400000\n"
     ]
    }
   ],
   "source": [
    "print(\"test sessions: \",len(test.sessions))\n",
    "print(\"train sessions: \",len(train.sessions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtest.sessions: \u001b[39m\u001b[39m\"\u001b[39m,(test\u001b[39m.\u001b[39msessions[\u001b[39m0\u001b[39m:\u001b[39m5\u001b[39m]))\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtest.aid: \u001b[39m\u001b[39m\"\u001b[39m,(test\u001b[39m.\u001b[39maid[\u001b[39m0\u001b[39m:\u001b[39m10\u001b[39m]))\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtrain.sessions: \u001b[39m\u001b[39m\"\u001b[39m,(train\u001b[39m.\u001b[39msessions[\u001b[39m0\u001b[39m:\u001b[39m5\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"test.sessions: \",(test.sessions[0:5]))\n",
    "print(\"test.aid: \",(test.aid[0:10]))\n",
    "\n",
    "\n",
    "print(\"train.sessions: \",(train.sessions[0:5]))\n",
    "print(\"train.aid: \",(train.aid[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_full_dt3.dat', 'wb') as f:\n",
    "    pickle.dump(train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1048733, {11840352, 11978145, 11895717, 11916787, 11669717, 11953302}, {11953302}, None]\n",
      "[470, {13260258, 12949881, 13233561}, None, None]\n"
     ]
    }
   ],
   "source": [
    "print(train.products[110])\n",
    "\n",
    "print(test.products[200])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90912879824f678a927bbb77a5f5f39c19065948c0c15f812c2f0fa4c4f160c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
